{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from model.mobilenet_v3 import MobileNetV3\n",
    "# from model.mobilenet_v2 import MobileNetV2\n",
    "# from model.AudioClassifier import AudioClassifier\n",
    "\n",
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_x = np.exp(x - c)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    y = exp_x / sum_exp_x\n",
    "    return y\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model_file = f'./weights/class{num_classes}/epoch_070.pt'\n",
    "\n",
    "# model = AudioClassifier(w=256, h=128, classes=21, num_conv_layers=3).to(device)\n",
    "# model = MobileNetV2((1, 128, 100), 21).to(device)\n",
    "model = MobileNetV3((1, 128, 256), num_classes, width_multiplier=1.0, dropout_rate=0).to(device)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.eval()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:e:/dataset/BabyCryDetectorSamples/1.wav slices: 16 confs len:16 class:[1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/2.wav slices: 8 confs len:8 class:[0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/3.wav slices: 5 confs len:5 class:[0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/4.wav slices: 17 confs len:17 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/5.wav slices: 12 confs len:12 class:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/6.wav slices: 30 confs len:30 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/7.wav slices: 26 confs len:26 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/8.wav slices: 21 confs len:21 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/9.wav slices: 28 confs len:28 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/10.wav slices: 8 confs len:8 class:[0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/11.wav slices: 13 confs len:13 class:[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/12.wav slices: 27 confs len:27 class:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/13.wav slices: 7 confs len:7 class:[0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/14.wav slices: 49 confs len:49 class:[1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/15.wav slices: 1 confs len:1 class:[0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/16.wav slices: 29 confs len:29 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/17.wav slices: 95 confs len:95 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/18.wav slices: 3 confs len:3 class:[0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/19.wav slices: 5 confs len:5 class:[0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/20.wav slices: 80 confs len:80 class:[1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 1 0 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/21.wav slices: 6 confs len:6 class:[0 0 0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/26.wav slices: 3 confs len:3 class:[1 1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/27.wav slices: 4 confs len:4 class:[0 0 0 0]\n",
      "file:e:/dataset/BabyCryDetectorSamples/28.wav slices: 2 confs len:2 class:[1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/29.wav slices: 2 confs len:2 class:[1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/30.wav slices: 3 confs len:3 class:[1 1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/31.wav slices: 2 confs len:2 class:[1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/32.wav slices: 4 confs len:4 class:[1 1 1 1]\n",
      "file:e:/dataset/BabyCryDetectorSamples/33.wav slices: 14 confs len:14 class:[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from utils.audio import *\n",
    "\n",
    "def predict(model, file):\n",
    "    wav, sr = librosa.load(file, sr=24000)\n",
    "    wav, _ = wav_trim(wav)\n",
    "    spec = wav_to_spectrogram(torch.Tensor(wav), 512, 512, 256, 128)\n",
    "    slices = spectrogram_split(spec.detach().cpu().numpy(), [256], [128], 256)\n",
    "\n",
    "    # print(slices[0].shape)\n",
    "    # print(slices[1].shape)\n",
    "    result = []\n",
    "    for i in range(len(slices)):\n",
    "        x = torch.from_numpy(slices[i]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        result.append(softmax(model(x).detach().cpu().numpy()))\n",
    "\n",
    "    confs = np.array([np.max(m) for m in result])\n",
    "    label = np.array([np.argmax(m) for m in result])\n",
    "    label[confs < 0.6] = -1\n",
    "    \n",
    "    filtered_indices = np.where(label >= 0)\n",
    "    filtered_confs = confs[filtered_indices]\n",
    "    filtered_label = label[filtered_indices]\n",
    "    \n",
    "    # 计算每个值出现的次数\n",
    "    values, counts = np.unique(label, return_counts=True)\n",
    "\n",
    "    # 按出现次数从多到少排序\n",
    "    sorted_indices = np.argsort(-counts)\n",
    "    sorted_values = values[sorted_indices]\n",
    "    sorted_counts = counts[sorted_indices]\n",
    "    \n",
    "    cls = sorted_values[0]\n",
    "    cnf = sorted_counts[0] / len(label)\n",
    "\n",
    "    # result = [-1] * len(conf)\n",
    "    # result[conf > 0.6] = 1\n",
    "    # result = [np.argmax(m) for m in result]\n",
    "    print(f'file:{file} slices: {len(slices)} confs len:{len(confs)} class:{filtered_label}')\n",
    "\n",
    "for i in range(1, 34):\n",
    "    file = f'e:/dataset/BabyCryDetectorSamples/{i}.wav'\n",
    "    if os.path.exists(file):\n",
    "        predict(model, file)\n",
    "\n",
    "# predict(model, 'e:/dataset/testing/cry1.mp3')\n",
    "# predict(model, 'e:/dataset/testing/cry2.mp3')\n",
    "# predict(model, 'e:/dataset/testing/dogbark1.wav')\n",
    "# predict(model, 'e:/dataset/testing/shortbark.wav')\n",
    "# predict(model, 'e:/dataset/BabyCryDetectorSamples/30.wav')\n",
    "# predict(model, 'e:/dataset/BabyCryDetectorSamples/31.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'e:/dataset/testing/cry2.mp3'\n",
    "\n",
    "wav, sr = librosa.load(test_file, sr=24000)\n",
    "wav = wav_trim(wav)\n",
    "spec = wav_to_spectrogram(test_file, 24000, 512, 512, 256, 128)\n",
    "slices = spectrogram_split(spec[0].detach().cpu().numpy(), [256], [128], 256)\n",
    "\n",
    "print(len(slices))\n",
    "# print(slices[0].shape)\n",
    "# print(slices[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
