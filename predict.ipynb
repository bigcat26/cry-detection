{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from model.mobilenet_v3 import MobileNetV3\n",
    "# from model.mobilenet_v2 import MobileNetV2\n",
    "from utils.modelproxy import ModelProxy\n",
    "\n",
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_x = np.exp(x - c)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    y = exp_x / sum_exp_x\n",
    "    return y\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model_file = './weights/mobilenetv3-binary/epoch_120.pt'\n",
    "model = ModelProxy(MobileNetV3((1, 128, 256), num_classes, width_multiplier=1.0, dropout_rate=0))\n",
    "model.to(device)\n",
    "model.load(model_file)\n",
    "model.eval()\n",
    "\n",
    "# model = AudioClassifier(w=256, h=128, classes=21, num_conv_layers=3).to(device)\n",
    "# model = MobileNetV2((1, 128, 100), 21).to(device)\n",
    "\n",
    "print(f'The model has {model.count_parameters():,} trainable parameters')\n",
    "# model.save_torchscript('torchscript.pt', trace_input_shape=(1, 1, 128, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\condaenv\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(f)[\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m audio_extentions:\n\u001b[0;32m     54\u001b[0m                     predict(model, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mdir\u001b[39m, f))\n\u001b[1;32m---> 56\u001b[0m walk_dir(\u001b[39m'\u001b[39;49m\u001b[39me:/dataset/baby_cry_detection_data\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m, in \u001b[0;36mwalk_dir\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(f)[\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m audio_extentions:\n\u001b[1;32m---> 54\u001b[0m         predict(model, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mdir\u001b[39;49m, f))\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, file)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(model, file):\n\u001b[1;32m----> 5\u001b[0m     wav, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(file, sr\u001b[39m=\u001b[39m\u001b[39m24000\u001b[39m)\n\u001b[0;32m      6\u001b[0m     wav, _ \u001b[39m=\u001b[39m wav_trim(wav)\n\u001b[0;32m      7\u001b[0m     spec \u001b[39m=\u001b[39m wav_to_spectrogram(torch\u001b[39m.\u001b[39mTensor(wav), \u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m128\u001b[39m)\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\lazy_loader\\__init__.py:77\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     75\u001b[0m submod_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpackage_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mattr_to_modules[name]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m submod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m---> 77\u001b[0m attr \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(submod, name)\n\u001b[0;32m     79\u001b[0m \u001b[39m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m# the module is accessible on the package.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\lazy_loader\\__init__.py:76\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     75\u001b[0m     submod_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpackage_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mattr_to_modules[name]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 76\u001b[0m     submod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(submod_path)\n\u001b[0;32m     77\u001b[0m     attr \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     79\u001b[0m     \u001b[39m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[39m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[39m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\librosa\\core\\audio.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudioread\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msignal\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msoxr\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlazy_loader\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlazy\u001b[39;00m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\signal\\__init__.py:333\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_spectral_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    332\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_wavelets\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m--> 333\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_peak_finding\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_czt\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwindows\u001b[39;00m \u001b[39mimport\u001b[39;00m get_window  \u001b[39m# keep this one in signal namespace\u001b[39;00m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msignal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_wavelets\u001b[39;00m \u001b[39mimport\u001b[39;00m cwt, ricker\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m scoreatpercentile\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_peak_finding_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     _local_maxima_1d,\n\u001b[0;32m     12\u001b[0m     _select_by_peak_distance,\n\u001b[0;32m     13\u001b[0m     _peak_prominences,\n\u001b[0;32m     14\u001b[0m     _peak_widths\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     18\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39margrelmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39margrelmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39margrelextrema\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpeak_prominences\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mpeak_widths\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfind_peaks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfind_peaks_cwt\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\stats\\_stats_py.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distributions\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _mstats_basic \u001b[39mas\u001b[39;00m mstats_basic\n\u001b[0;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_mstats_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[0;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\stats\\distributions.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_distn_infrastructure\u001b[39;00m \u001b[39mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _discrete_distns\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_continuous_distns\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mf:\\condaenv\\pytorch\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ufuncs\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mscu\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m _lazyselect, _lazywhere\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _stats\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_tukeylambda_stats\u001b[39;00m \u001b[39mimport\u001b[39;00m (tukeylambda_variance \u001b[39mas\u001b[39;00m _tlvar,\n\u001b[0;32m     25\u001b[0m                                  tukeylambda_kurtosis \u001b[39mas\u001b[39;00m _tlkurt)\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_distn_infrastructure\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     get_distribution_names, _kurtosis,\n\u001b[0;32m     28\u001b[0m     rv_continuous, _skew, _get_fixed_fit_value, _check_shape, _ShapeInfo)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from utils.audio import *\n",
    "\n",
    "def predict(model, file):\n",
    "    wav, sr = librosa.load(file, sr=24000)\n",
    "    wav, _ = wav_trim(wav)\n",
    "    spec = wav_to_spectrogram(torch.Tensor(wav), 512, 512, 256, 128)\n",
    "    slices = spectrogram_split(spec.detach().cpu().numpy(), [256], [128], 256)\n",
    "\n",
    "    # print(slices[0].shape)\n",
    "    # print(slices[1].shape)\n",
    "    result = []\n",
    "    for i in range(len(slices)):\n",
    "        x = torch.from_numpy(slices[i]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        result.append(softmax(model(x).detach().cpu().numpy()))\n",
    "\n",
    "    confs = np.array([np.max(m) for m in result])\n",
    "    label = np.array([np.argmax(m) for m in result])\n",
    "    label[confs < 0.6] = -1\n",
    "    \n",
    "    filtered_indices = np.where(label >= 0)\n",
    "    filtered_confs = confs[filtered_indices]\n",
    "    filtered_label = label[filtered_indices]\n",
    "    \n",
    "    # 计算每个值出现的次数\n",
    "    values, counts = np.unique(label, return_counts=True)\n",
    "\n",
    "    # 按出现次数从多到少排序\n",
    "    sorted_indices = np.argsort(-counts)\n",
    "    sorted_values = values[sorted_indices]\n",
    "    sorted_counts = counts[sorted_indices]\n",
    "    \n",
    "    cls = sorted_values[0]\n",
    "    cnf = sorted_counts[0] / len(label)\n",
    "\n",
    "    # result = [-1] * len(conf)\n",
    "    # result[conf > 0.6] = 1\n",
    "    # result = [np.argmax(m) for m in result]\n",
    "    print(f'file:{file} slices: {len(slices)} confs len:{len(confs)} class:{filtered_label}')\n",
    "\n",
    "def walk_dir(dir):\n",
    "    # push dir to stack\n",
    "    dirs = []\n",
    "    audio_extentions = ['.wav', '.ogg', '.mp3']\n",
    "    dirs.append(dir)\n",
    "    while len(dirs) > 0:\n",
    "        dir = dirs.pop()\n",
    "        files = os.listdir(dir)\n",
    "        for f in files:\n",
    "            if os.path.isdir(os.path.join(dir, f)):\n",
    "                dirs.append(os.path.join(dir, f))\n",
    "            else:\n",
    "                if os.path.splitext(f)[1] in audio_extentions:\n",
    "                    predict(model, os.path.join(dir, f))\n",
    "\n",
    "walk_dir('e:/dataset/baby_cry_detection_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'e:/dataset/testing/cry2.mp3'\n",
    "\n",
    "wav, sr = librosa.load(test_file, sr=24000)\n",
    "wav = wav_trim(wav)\n",
    "spec = wav_to_spectrogram(test_file, 24000, 512, 512, 256, 128)\n",
    "slices = spectrogram_split(spec[0].detach().cpu().numpy(), [256], [128], 256)\n",
    "\n",
    "print(len(slices))\n",
    "# print(slices[0].shape)\n",
    "# print(slices[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
