{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20f395-b21c-4a62-9d8d-c3c17a00319c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/karoldvl/ESC-50/archive/master.zip\n",
    "# !mkdir -p data && cd data && unzip ../master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41dd4900-bbd6-41da-864a-c30a0a568f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:11610\n",
      "test_dataset:2894\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from utils.transform import UnsqueezeTransform, NoiseGeneratorTransform, FixedValueTransform\n",
    "from utils.dataset import dump_dataset_info\n",
    "from dataset.cry import CryDataset\n",
    "from dataset.noise import NoiseDataset\n",
    "\n",
    "\n",
    "# 定义超参数\n",
    "classes = 50\n",
    "train_batch_size = 300\n",
    "test_batch_size = 5\n",
    "train_data_esc50 = 'e:/dataset/out/esc50pp/training128mel1.pkl'\n",
    "valid_data_esc50 = 'e:/dataset/out/esc50pp/validation128mel1.pkl'\n",
    "train_data_donateacry = 'e:/dataset/out/dnac/donateacry.pkl'\n",
    "\n",
    "train_data_us8k = 'e:/dataset/out/us8k/training128mel1.pkl'\n",
    "valid_data_us8k = 'e:/dataset/out/us8k/validation128mel1.pkl'\n",
    "\n",
    "#\n",
    "# classes = 51\n",
    "#   label[51] = 'noise'\n",
    "#\n",
    "\n",
    "noise = NoiseGeneratorTransform()\n",
    "\n",
    "def get_noise_dataset(shape=(1, 128, 256), num_samples=6000):\n",
    "    return NoiseDataset(shape, num_samples, target_id=51, noise_std=0.1)\n",
    "\n",
    "def get_donateacry_dataset():\n",
    "    return CryDataset(train_data_donateacry,\n",
    "                      transform=torch.nn.Sequential(\n",
    "                          noise, \n",
    "                          # NormalizeTransform(),\n",
    "                          UnsqueezeTransform(),\n",
    "                      ), \n",
    "                      target_transform=FixedValueTransform(value=20)\n",
    "                     )\n",
    "\n",
    "def get_esc50_train_dataset():\n",
    "    return CryDataset(train_data_esc50, \n",
    "                      transform=torch.nn.Sequential(\n",
    "                          noise, \n",
    "                          # NormalizeTransform(),\n",
    "                          UnsqueezeTransform(),\n",
    "                      ), \n",
    "                      # target_transform=ESC50LabelTransform()\n",
    "                     )\n",
    "\n",
    "def get_esc50_valid_dataset():\n",
    "    return CryDataset(valid_data_esc50,\n",
    "                      transform=torch.nn.Sequential(\n",
    "                          #  NormalizeTransform(),\n",
    "                          UnsqueezeTransform(),\n",
    "                      ), \n",
    "                      #  target_transform=ESC50LabelTransform()\n",
    "                     )\n",
    "\n",
    "def get_us8k_train_dataset():\n",
    "    return CryDataset(train_data_us8k, \n",
    "                      transform=torch.nn.Sequential(\n",
    "                          noise, \n",
    "                          #  NormalizeTransform(),\n",
    "                          UnsqueezeTransform(),\n",
    "                      ), \n",
    "                    #   target_transform=US8KLabelTransform()\n",
    "                     )\n",
    "\n",
    "def get_us8k_valid_dataset():\n",
    "    return CryDataset(valid_data_us8k,\n",
    "                      transform=torch.nn.Sequential(\n",
    "                          #  NormalizeTransform(),\n",
    "                          UnsqueezeTransform(),\n",
    "                      ), \n",
    "                    #   target_transform=US8KLabelTransform()\n",
    "                     )\n",
    "def get_big_valid_dataset():\n",
    "    return ConcatDataset([get_esc50_valid_dataset(), get_us8k_valid_dataset()])\n",
    "\n",
    "train_loader = DataLoader(ConcatDataset([\n",
    "                                get_esc50_train_dataset(),\n",
    "                                # get_donateacry_dataset(),\n",
    "                                # get_noise_dataset(num_samples=300)\n",
    "                            ]), \n",
    "                          batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(ConcatDataset([\n",
    "                                get_esc50_valid_dataset(),\n",
    "                            ]), \n",
    "                          batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "print(f'train_dataset:{len(train_loader.dataset)}')\n",
    "print(f'test_dataset:{len(test_loader.dataset)}')\n",
    "# dump_dataset_info(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0555ac-f9d2-4360-a5f1-b4d5e7eca991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, lr=0.001\n",
      "Epoch [1/100], LR:[0.001] NL:1e-06 Loss:7.9744 Train Accuracy:3.99% Test Accuracy:2.35%\n",
      "Epoch [2/100], LR:[0.001] NL:1e-06 Loss:7.0543 Train Accuracy:39.15% Test Accuracy:27.16%\n",
      "Epoch [3/100], LR:[0.001] NL:1e-06 Loss:6.4236 Train Accuracy:51.65% Test Accuracy:37.91%\n",
      "Epoch [4/100], LR:[0.001] NL:1e-06 Loss:5.8408 Train Accuracy:66.03% Test Accuracy:47.13%\n",
      "Epoch [5/100], LR:[0.001] NL:1e-06 Loss:5.4146 Train Accuracy:69.22% Test Accuracy:46.20%\n",
      "Epoch [6/100], LR:[0.001] NL:1e-06 Loss:5.0196 Train Accuracy:72.98% Test Accuracy:46.20%\n",
      "Epoch [7/100], LR:[0.001] NL:1e-06 Loss:4.8299 Train Accuracy:76.80% Test Accuracy:46.86%\n",
      "Epoch [8/100], LR:[0.001] NL:1e-06 Loss:4.5591 Train Accuracy:84.22% Test Accuracy:51.35%\n",
      "Epoch [9/100], LR:[0.001] NL:1e-06 Loss:4.3801 Train Accuracy:76.40% Test Accuracy:47.51%\n",
      "Epoch [10/100], LR:[0.001] NL:1e-06 Loss:4.1711 Train Accuracy:81.94% Test Accuracy:48.31%\n",
      "Epoch [11/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.1197 Train Accuracy:99.61% Test Accuracy:61.40%\n",
      "Epoch [12/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.0659 Train Accuracy:99.68% Test Accuracy:61.78%\n",
      "Epoch [13/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.0350 Train Accuracy:99.72% Test Accuracy:61.51%\n",
      "Epoch [14/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.0291 Train Accuracy:99.78% Test Accuracy:61.78%\n",
      "Epoch [15/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.0013 Train Accuracy:99.83% Test Accuracy:61.71%\n",
      "Epoch [16/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:4.0056 Train Accuracy:99.82% Test Accuracy:62.54%\n",
      "Epoch [17/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.9718 Train Accuracy:99.89% Test Accuracy:62.02%\n",
      "Epoch [18/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.9375 Train Accuracy:99.91% Test Accuracy:61.82%\n",
      "Epoch [19/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.9189 Train Accuracy:99.92% Test Accuracy:62.37%\n",
      "Epoch [20/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.9188 Train Accuracy:99.92% Test Accuracy:60.71%\n",
      "Epoch [21/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.9121 Train Accuracy:99.92% Test Accuracy:62.37%\n",
      "Epoch [22/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.8771 Train Accuracy:99.95% Test Accuracy:62.09%\n",
      "Epoch [23/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.8555 Train Accuracy:99.96% Test Accuracy:62.23%\n",
      "Epoch [24/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.8376 Train Accuracy:99.97% Test Accuracy:61.58%\n",
      "Epoch [25/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.8244 Train Accuracy:99.95% Test Accuracy:62.20%\n",
      "Epoch [26/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.8017 Train Accuracy:99.95% Test Accuracy:62.23%\n",
      "Epoch [27/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.7885 Train Accuracy:99.96% Test Accuracy:62.06%\n",
      "Epoch [28/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.7684 Train Accuracy:99.97% Test Accuracy:61.89%\n",
      "Epoch [29/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.7412 Train Accuracy:99.99% Test Accuracy:61.16%\n",
      "Epoch [30/100], LR:[0.0001] NL:9.999999999999999e-06 Loss:3.7278 Train Accuracy:99.99% Test Accuracy:62.44%\n",
      "Epoch [31/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7228 Train Accuracy:99.99% Test Accuracy:63.03%\n",
      "Epoch [32/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7237 Train Accuracy:99.99% Test Accuracy:62.51%\n",
      "Epoch [33/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7200 Train Accuracy:99.99% Test Accuracy:62.85%\n",
      "Epoch [34/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7218 Train Accuracy:100.00% Test Accuracy:62.54%\n",
      "Epoch [35/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7212 Train Accuracy:99.99% Test Accuracy:62.27%\n",
      "Epoch [36/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7355 Train Accuracy:99.99% Test Accuracy:62.30%\n",
      "Epoch [37/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7135 Train Accuracy:99.99% Test Accuracy:62.54%\n",
      "Epoch [38/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7195 Train Accuracy:99.99% Test Accuracy:62.54%\n",
      "Epoch [39/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7098 Train Accuracy:99.99% Test Accuracy:62.99%\n",
      "Epoch [40/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7103 Train Accuracy:100.00% Test Accuracy:62.20%\n",
      "Epoch [41/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7076 Train Accuracy:100.00% Test Accuracy:62.30%\n",
      "Epoch [42/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7024 Train Accuracy:100.00% Test Accuracy:62.40%\n",
      "Epoch [43/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7013 Train Accuracy:99.99% Test Accuracy:62.34%\n",
      "Epoch [44/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7029 Train Accuracy:100.00% Test Accuracy:62.92%\n",
      "Epoch [45/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7000 Train Accuracy:99.99% Test Accuracy:62.47%\n",
      "Epoch [46/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6957 Train Accuracy:100.00% Test Accuracy:62.58%\n",
      "Epoch [47/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6897 Train Accuracy:100.00% Test Accuracy:62.58%\n",
      "Epoch [48/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6912 Train Accuracy:100.00% Test Accuracy:62.72%\n",
      "Epoch [49/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6918 Train Accuracy:100.00% Test Accuracy:62.54%\n",
      "Epoch [50/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6820 Train Accuracy:99.99% Test Accuracy:62.82%\n",
      "Epoch [51/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.7012 Train Accuracy:100.00% Test Accuracy:61.92%\n",
      "Epoch [52/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6972 Train Accuracy:100.00% Test Accuracy:62.16%\n",
      "Epoch [53/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6902 Train Accuracy:100.00% Test Accuracy:62.06%\n",
      "Epoch [54/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6827 Train Accuracy:99.99% Test Accuracy:62.72%\n",
      "Epoch [55/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6764 Train Accuracy:100.00% Test Accuracy:62.40%\n",
      "Epoch [56/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6768 Train Accuracy:100.00% Test Accuracy:62.61%\n",
      "Epoch [57/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6759 Train Accuracy:100.00% Test Accuracy:62.75%\n",
      "Epoch [58/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6693 Train Accuracy:100.00% Test Accuracy:62.44%\n",
      "Epoch [59/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6643 Train Accuracy:100.00% Test Accuracy:62.58%\n",
      "Epoch [60/100], LR:[1e-05] NL:9.999999999999999e-05 Loss:3.6740 Train Accuracy:100.00% Test Accuracy:62.58%\n",
      "Epoch [61/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6697 Train Accuracy:100.00% Test Accuracy:62.34%\n",
      "Epoch [62/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6691 Train Accuracy:100.00% Test Accuracy:62.58%\n",
      "Epoch [63/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6654 Train Accuracy:100.00% Test Accuracy:62.02%\n",
      "Epoch [64/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6786 Train Accuracy:100.00% Test Accuracy:62.44%\n",
      "Epoch [65/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6639 Train Accuracy:100.00% Test Accuracy:62.85%\n",
      "Epoch [66/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6641 Train Accuracy:100.00% Test Accuracy:62.79%\n",
      "Epoch [67/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6646 Train Accuracy:100.00% Test Accuracy:62.51%\n",
      "Epoch [68/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6675 Train Accuracy:100.00% Test Accuracy:62.20%\n",
      "Epoch [69/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6753 Train Accuracy:100.00% Test Accuracy:63.13%\n",
      "Epoch [70/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6621 Train Accuracy:100.00% Test Accuracy:62.23%\n",
      "Epoch [71/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6649 Train Accuracy:100.00% Test Accuracy:62.13%\n",
      "Epoch [72/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6613 Train Accuracy:100.00% Test Accuracy:62.44%\n",
      "Epoch [73/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6604 Train Accuracy:100.00% Test Accuracy:62.16%\n",
      "Epoch [74/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6654 Train Accuracy:100.00% Test Accuracy:62.37%\n",
      "Epoch [75/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6768 Train Accuracy:100.00% Test Accuracy:62.79%\n",
      "Epoch [76/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6695 Train Accuracy:100.00% Test Accuracy:62.40%\n",
      "Epoch [77/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6646 Train Accuracy:100.00% Test Accuracy:61.99%\n",
      "Epoch [78/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6685 Train Accuracy:100.00% Test Accuracy:62.13%\n",
      "Epoch [79/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6661 Train Accuracy:100.00% Test Accuracy:62.37%\n",
      "Epoch [80/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6673 Train Accuracy:100.00% Test Accuracy:62.34%\n",
      "Epoch [81/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6624 Train Accuracy:100.00% Test Accuracy:62.82%\n",
      "Epoch [82/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6582 Train Accuracy:100.00% Test Accuracy:62.34%\n",
      "Epoch [83/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6822 Train Accuracy:100.00% Test Accuracy:61.99%\n",
      "Epoch [84/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6594 Train Accuracy:100.00% Test Accuracy:62.65%\n",
      "Epoch [85/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6558 Train Accuracy:100.00% Test Accuracy:62.54%\n",
      "Epoch [86/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6631 Train Accuracy:100.00% Test Accuracy:62.02%\n",
      "Epoch [87/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6608 Train Accuracy:100.00% Test Accuracy:61.89%\n",
      "Epoch [88/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6668 Train Accuracy:100.00% Test Accuracy:61.85%\n",
      "Epoch [89/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6802 Train Accuracy:100.00% Test Accuracy:62.30%\n",
      "Epoch [90/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6727 Train Accuracy:100.00% Test Accuracy:62.96%\n",
      "Epoch [91/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6680 Train Accuracy:100.00% Test Accuracy:63.34%\n",
      "Epoch [92/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6629 Train Accuracy:100.00% Test Accuracy:63.34%\n",
      "Epoch [93/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6549 Train Accuracy:100.00% Test Accuracy:62.65%\n",
      "Epoch [94/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6547 Train Accuracy:100.00% Test Accuracy:62.34%\n",
      "Epoch [95/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6616 Train Accuracy:100.00% Test Accuracy:63.17%\n",
      "Epoch [96/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6647 Train Accuracy:100.00% Test Accuracy:63.10%\n",
      "Epoch [97/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6687 Train Accuracy:100.00% Test Accuracy:62.02%\n",
      "Epoch [98/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6624 Train Accuracy:100.00% Test Accuracy:62.68%\n",
      "Epoch [99/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6673 Train Accuracy:100.00% Test Accuracy:62.34%\n",
      "Epoch [100/100], LR:[1.0000000000000002e-06] NL:0.001 Loss:3.6596 Train Accuracy:100.00% Test Accuracy:62.68%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# 混合精度\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from model.mobilenet_v3 import MobileNetV3\n",
    "from model.mobilenet_v2 import MobileNetV2\n",
    "from model.AudioClassifier import AudioClassifier\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = AudioClassifier(w=256, h=128, classes=21, num_conv_layers=3).to(device)\n",
    "# model = MobileNetV2((1, 128, 100), 21).to(device)\n",
    "model = MobileNetV3((1, 128, 256), classes, width_multiplier=1.0, dropout_rate=0.2).to(device)\n",
    "# print(model)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "\n",
    "with_tqdm = False\n",
    "with_l2_regularization = True\n",
    "with_grad_scaler = True\n",
    "start_epoch = 0\n",
    "end_epoch = 100\n",
    "learning_rate = 1e-3\n",
    "save_model_start = 10\n",
    "save_model_period = 10\n",
    "\n",
    "# L2 正则化系数\n",
    "l2_reg = 0.01\n",
    "\n",
    "\n",
    "model_name = f'class{classes}'\n",
    "model_folder = f'./weights/{model_name}'\n",
    "model_pattern = f'{model_folder}/epoch_{{epoch:03d}}.pt'\n",
    "\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "if os.path.exists(model_pattern.format(epoch=start_epoch)):\n",
    "    print(f'loading model: {model_pattern.format(epoch=start_epoch)}')\n",
    "    model.load_state_dict(torch.load(model_pattern.format(epoch=start_epoch)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "scheduler = MultiStepLR(optimizer, milestones=[10, 30, 60], gamma=0.1)\n",
    "\n",
    "def evalute(model, dataloader):\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            # print(f'test[{i}]: actual={y[0]} predicted={predicted[0]}')\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        # print(f'Accuracy: {accuracy:.2f}%')\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "# 创建 GradScaler\n",
    "if with_grad_scaler:\n",
    "    scaler = GradScaler()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# 训练模型\n",
    "print(f'Training, lr={learning_rate}')\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    model.train()\n",
    "    iteratable = tqdm(enumerate(train_loader)) if with_tqdm else enumerate(train_loader)\n",
    "    for i, (inputs, targets) in iteratable:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 前向过程开启 autocast\n",
    "        with autocast():\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "        # 添加 L2 正则化\n",
    "        if with_l2_regularization:\n",
    "            l2_loss = 0\n",
    "            for param in model.parameters():\n",
    "                l2_loss += torch.norm(param)\n",
    "            loss += l2_reg * l2_loss\n",
    "\n",
    "        # 反向传播在 autocast 上下文之外\n",
    "        optimizer.zero_grad()\n",
    "        if with_grad_scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if (epoch + 1) >= save_model_start and (epoch + 1) % save_model_period == 0:\n",
    "        torch.save(model.state_dict(), model_pattern.format(epoch=epoch + 1))\n",
    "\n",
    "    train_acc = evalute(model, train_loader)\n",
    "    test_acc = evalute(model, test_loader)\n",
    "\n",
    "    writer.add_scalar('Loss', loss, epoch)\n",
    "    writer.add_scalar('Train Accuracy', train_acc, epoch)\n",
    "    writer.add_scalar('Test Accuracy', test_acc, epoch)\n",
    "    print(f'Epoch [{epoch+1}/{end_epoch}], LR:{scheduler.get_last_lr()} NL:{noise.get_level()} Loss:{loss.item():.4f} Accuracy/Train:{train_acc:.2f}% Accuracy/Test:{test_acc:.2f}%')\n",
    "    \n",
    "    noise.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.load_state_dict(torch.load('./model_epoch_40.pt'))\n",
    "print(f'Final Test Accuracy: {evalute(model, test_loader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69597e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "waveform, sr = torchaudio.load('E:/dataset/ESC-50-master/audio/1-100032-A-0.wav')\n",
    "resample = torchaudio.transforms.Resample(sr, 8000)\n",
    "spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=8000,\n",
    "    n_fft=512,\n",
    "    win_length=20,\n",
    "    hop_length=10, \n",
    "    n_mels=128)\n",
    "\n",
    "eps = torch.Tensor([1e-6])\n",
    "# spec = spec.numpy()\n",
    "# spec = np.log(spec + eps)\n",
    "\n",
    "\n",
    "out = spectrogram(resample(waveform[:44100]))\n",
    "out += eps\n",
    "out = out.log()\n",
    "# time = len(out[0]) * 1000 / 8000\n",
    "# print(time)\n",
    "# print(out.shape)\n",
    "\n",
    "plt.pcolormesh(out[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from AudioClassifier import AudioClassifier\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = AudioClassifier(w=128, h=100, classes=21, num_conv_layers=3).to(device)\n",
    "model.load_state_dict(torch.load('models/audioclassifier3/epoch_100.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c66696-84b2-4d5b-a87b-6aa328fede55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def get_spec(waveform, sampling_rate=24000, n_fft=512, window_length=20, hop_length=10):\n",
    "\tspecs = []\n",
    "\twaveform = torch.Tensor(waveform)\n",
    "\ttransform = torchaudio.transforms.MelSpectrogram(\n",
    "\t\tsample_rate=sampling_rate, \n",
    "\t\tn_fft=n_fft, \n",
    "\t\twin_length=window_length, \n",
    "\t\thop_length=hop_length, \n",
    "\t\tn_mels=128)\n",
    "\tspec = transform(waveform)\n",
    "\teps = 1e-6\n",
    "\tspec = spec.numpy()\n",
    "\tspec = np.log(spec + eps)\n",
    "\tx_min = spec.min()\n",
    "\tx_max = spec.max()\n",
    "\tspec = (spec - x_min) / (x_max - x_min)\n",
    "\tfor j in range(0, spec.shape[1] - 51, 50):\n",
    "\t\tslice = spec[:, j:j+100]\n",
    "\t\t# print(f'slice shape: {slice.shape}, range: {j}:{j+100}')\n",
    "\t\tspecs.append(slice)\n",
    "\treturn specs\n",
    "\n",
    "def extract_spectrogram(values, clip, entries):\n",
    "\tfor data in entries:\n",
    "\n",
    "\t\tnum_channels = 2\n",
    "\t\twindow_sizes = [20, 40]\n",
    "\t\thop_sizes = [10, 20]\n",
    "\t\t# window_sizes = [20]\n",
    "\t\t# hop_sizes = [10]\n",
    "\n",
    "\t\tspecs = []\n",
    "\t\tfor i in range(num_channels):\n",
    "\t\t\twindow_length = int(round(window_sizes[i]*args.sampling_rate/1000))\n",
    "\t\t\thop_length = int(round(hop_sizes[i]*args.sampling_rate/1000))\n",
    "\n",
    "\t\t\tclip = torch.Tensor(clip)\n",
    "\t\t\tspec = torchaudio.transforms.MelSpectrogram(sample_rate=args.sampling_rate, n_fft=512, win_length=window_length, hop_length=hop_length, n_mels=128)(clip)\n",
    "\t\t\teps = 1e-6\n",
    "\t\t\tspec = spec.numpy()\n",
    "\t\t\tspec = np.log(spec + eps)\n",
    "\t\t\t# print(f'channel: {i} shape: {spec.shape}')\n",
    "\t\t\tfor j in range(0, spec.shape[1] - 51, 50):\n",
    "\t\t\t\tslice = spec[:, j:j+100]\n",
    "\t\t\t\t# print(f'slice shape: {slice.shape}, range: {j}:{j+100}')\n",
    "\t\t\t\tspecs.append(slice)\n",
    "\t\t\t# print(spec.shape)\n",
    "\t\t\t# spec = np.asarray(torchvision.transforms.Resize((128, 250))(Image.fromarray(spec)))\n",
    "\t\t\t# specs.append(spec)\n",
    "\t\tnew_entry = {}\n",
    "\t\t# new_entry[\"audio\"] = clip.numpy()\n",
    "\t\tnew_entry[\"values\"] = np.array(specs)\n",
    "\t\tnew_entry[\"target\"] = data[\"target\"]\n",
    "\t\tvalues.append(new_entry)\n",
    "\n",
    "clip, sr = librosa.load(\"d:\\\\code\\\\jupyter\\\\audio\\\\positive\\\\baby_cry_16bit_8k.wav\", sr=24000)\n",
    "# clip, sr = librosa.load(\"E:\\\\dataset\\\\bilibili\\\\cry2.m4s\", sr=24000)\n",
    "print(clip.shape, sr)\n",
    "clip = clip[:len(clip) // 1000 * 1000]\n",
    "print(clip.shape)\n",
    "# entries = audios.loc[audios[\"filename\"]==audio].to_dict(orient=\"records\")\n",
    "values = get_spec(clip, sampling_rate=sr)\n",
    "values = [np.expand_dims(value, 0) for value in values[:1000]]\n",
    "values = torch.Tensor(values).to(device)\n",
    "print(values.size())\n",
    "# print(len(values))\n",
    "# print(values[0].shape)\n",
    "\n",
    "predict = model(values).detach().cpu().numpy()\n",
    "predict = [np.argmax(p) for p in predict]\n",
    "print(predict)\n",
    "# print(torch.argmax(predict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc942ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'audio length: {7659000 / 8000}s')\n",
    "# print(7659000 / 1990)\n",
    "print(predict.index(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
